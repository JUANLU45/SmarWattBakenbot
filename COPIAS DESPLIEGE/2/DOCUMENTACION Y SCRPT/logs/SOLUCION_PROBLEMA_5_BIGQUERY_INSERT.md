# AN√ÅLISIS Y SOLUCI√ìN DEL PROBLEMA 5: FALLO SILENCIOSO DE INSERCI√ìN EN BIGQUERY

## 1. RESUMEN DEL PROBLEMA

Se ha identificado un error silencioso pero cr√≠tico en los logs del servicio `energy-ia-api`. El error `ERROR - ? Error insertando en BigQuery:` aparece despu√©s de generar una recomendaci√≥n de tarifa.

Este fallo no interrumpe el flujo del usuario (no genera un error 500), pero impide que los datos de las recomendaciones generadas se guarden en la base de datos. A nivel empresarial, esto es extremadamente grave, ya que se pierde informaci√≥n vital para el an√°lisis de negocio, la inteligencia de datos y el reentrenamiento de los modelos de IA.

## 2. AN√ÅLISIS Y VERIFICACI√ìN CONTRA EL C√ìDIGO (CERO ESPECULACI√ìN)

### A. Verificaci√≥n de Logs (Hecho)

- **Log:** `root - ERROR - ? Error insertando en BigQuery:`
- **Fuente del Log:** `energy-ia-api`
- **Timestamp:** `2025-08-01T13:28:32.475Z`
- **Contexto del Log:** El error ocurre inmediatamente despu√©s de que se genera una recomendaci√≥n, en el momento de persistir los resultados.
- **Conclusi√≥n del Log:** La operaci√≥n de escritura en la tabla de recomendaciones de BigQuery est√° fallando.

### B. Verificaci√≥n del C√≥digo de Inserci√≥n (Hecho)

- **Archivo Verificado:** `energy_ia_api_COPY/app/routes.py`
- **Funci√≥n Relevante:** `_log_recommendation` dentro de la clase `EnterpriseTariffRecommenderService`.
- **An√°lisis del C√≥digo:**
  1. La funci√≥n prepara un diccionario llamado `log_data` para la inserci√≥n.
  2. Este diccionario contiene, entre otros, los campos:
     - `record_date`: Creado a partir de `current_timestamp.date()`.
     - `total_savings`: Un duplicado del campo `estimated_annual_saving`.
  3. La funci√≥n intenta insertar este diccionario en la tabla `recommendation_log` de BigQuery.

### C. Identificaci√≥n de la Causa Ra√≠z (Verificado)

- **El Problema:** El esquema del objeto Python (`log_data`) que se intenta insertar no coincide con el esquema de la tabla de destino en BigQuery.
- **Evidencia Concluyente:** El c√≥digo est√° intentando escribir en columnas (`record_date`, `total_savings`) que no existen en la definici√≥n de la tabla de BigQuery. La API de BigQuery rechaza la inserci√≥n debido a esta discrepancia de esquemas, resultando en un error de tipo `BadRequest 400: no such field`. El sistema de logging gen√©rico captura este error y lo reporta como "Error insertando en BigQuery", ocultando el detalle espec√≠fico.

- **Conclusi√≥n Final de la Causa Ra√≠z:** La falta de sincronizaci√≥n entre el esquema de la aplicaci√≥n y el esquema de la base de datos es la causa directa del fallo de inserci√≥n.

## 3. PLAN DE ACCI√ìN DETALLADO (PROPUESTA DE SOLUCI√ìN EMPRESARIAL)

Para corregir este problema de forma robusta, escalable y siguiendo las mejores pr√°cticas de Infraestructura como C√≥digo (IaC), se crear√° un script de migraci√≥n de base de datos.

### Paso 1: Crear un Script de Migraci√≥n de Esquema

Se crear√° un nuevo archivo Python dedicado a gestionar las migraciones del esquema de BigQuery. Este script ser√° la √∫nica fuente de verdad para la estructura de la base de datos.

- **Nuevo Archivo:** `BQ-tablas/bq_migrations/V2__add_recommendation_fields.py`
- **Contenido del Script:**

```python
# BQ-tablas/bq_migrations/V2__add_recommendation_fields.py
import os
from google.cloud import bigquery
from google.api_core.exceptions import NotFound

# --- CONFIGURACI√ìN EMPRESARIAL ROBUSTA ---
# Usar variables de entorno para m√°xima flexibilidad
PROJECT_ID = os.environ.get("GCP_PROJECT_ID", "tu-proyecto-gcp")
DATASET_ID = os.environ.get("BQ_DATASET_ID", "smartwatt_data")
TABLE_ID = os.environ.get("BQ_RECOMMENDATION_LOG_TABLE_ID", "recommendation_log")

# --- CLIENTE BIGQUERY ---
client = bigquery.Client(project=PROJECT_ID)

def run_migration():
    """
    A√±ade las columnas 'record_date' y 'total_savings' a la tabla de logs de recomendaciones.
    Es idempotente: no falla si las columnas ya existen.
    """
    print("üöÄ Iniciando migraci√≥n V2 para la tabla de recomendaciones...")

    table_ref = client.dataset(DATASET_ID).table(TABLE_ID)

    try:
        table = client.get_table(table_ref)
        print(f"‚úÖ Tabla '{TABLE_ID}' encontrada.")
    except NotFound:
        print(f"‚ùå ERROR: La tabla '{TABLE_ID}' no existe en el dataset '{DATASET_ID}'. No se puede migrar.")
        return

    original_schema = table.schema
    new_schema = original_schema[:]  # Crear una copia para modificar

    # --- DEFINICI√ìN DE NUEVOS CAMPOS ---
    # Usamos un diccionario para evitar duplicados y facilitar la comprobaci√≥n
    fields_to_add = {
        "record_date": bigquery.SchemaField("record_date", "DATE", mode="NULLABLE", description="Fecha de la recomendaci√≥n para particionamiento y an√°lisis."),
        "total_savings": bigquery.SchemaField("total_savings", "FLOAT", mode="NULLABLE", description="Ahorro total estimado (campo duplicado para an√°lisis hist√≥rico).")
    }

    # --- L√ìGICA IDEMPOTENTE ---
    # Comprobar si los campos ya existen antes de a√±adirlos
    existing_field_names = {field.name for field in original_schema}

    added_any_field = False
    for field_name, field_definition in fields_to_add.items():
        if field_name not in existing_field_names:
            print(f"   - A√±adiendo columna '{field_name}'...")
            new_schema.append(field_definition)
            added_any_field = True
        else:
            print(f"   - La columna '{field_name}' ya existe. Omitiendo.")

    # --- APLICAR CAMBIOS SOLO SI ES NECESARIO ---
    if added_any_field:
        table.schema = new_schema
        client.update_table(table, ["schema"])
        print("‚úÖ Migraci√≥n completada. El esquema de la tabla ha sido actualizado.")
    else:
        print("‚úÖ El esquema ya est√° actualizado. No se requieren cambios.")

if __name__ == "__main__":
    run_migration()

```

### Paso 2: Ejecutar la Migraci√≥n

Este script se ejecutar√° una vez en el entorno de producci√≥n (preferiblemente a trav√©s de un pipeline de CI/CD, pero manualmente por ahora) para actualizar el esquema de la tabla de forma segura.

### Paso 3: Eliminar C√≥digo Redundante (Refactorizaci√≥n)

El c√≥digo en `energy_ia_api_COPY/app/routes.py` tiene un campo redundante (`total_savings`). Se eliminar√° para mantener el c√≥digo limpio y evitar la duplicaci√≥n de datos.

1.  **Archivo a Modificar:** `energy_ia_api_COPY/app/routes.py`
2.  **Funci√≥n:** `_log_recommendation`
3.  **Cambio:** Eliminar la l√≠nea `"total_savings": recommendation["best_recommendation"]["cost_analysis"]["annual_savings"],` del diccionario `log_data`. El campo `estimated_annual_saving` ya contiene este valor.

## 4. IMPACTO Y VERIFICACI√ìN POST-IMPLEMENTACI√ìN

- **Impacto:** Se restaurar√° la integridad de los datos. Todas las nuevas recomendaciones se guardar√°n correctamente en BigQuery, habilitando el an√°lisis de datos y la inteligencia de negocio.
- **Verificaci√≥n:**
  1.  Despu√©s de ejecutar el script de migraci√≥n, se verificar√° el esquema de la tabla en la consola de Google Cloud para confirmar que las nuevas columnas existen.
  2.  Despu√©s de desplegar el cambio en el c√≥digo, se monitorear√°n los logs de `energy-ia-api` para confirmar que los errores de inserci√≥n en BigQuery han desaparecido por completo.
  3.  Se consultar√° la tabla `recommendation_log` en BigQuery para verificar que los nuevos registros se est√°n insertando correctamente con los nuevos campos poblados.

Este plan de acci√≥n no solo corrige el error, sino que introduce una pr√°ctica de gesti√≥n de bases de datos mucho m√°s robusta y profesional, fundamental para un sistema en producci√≥n.
