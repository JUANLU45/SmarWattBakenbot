# energy_ia_api_COPY/app/services/generative_chat_service.py
# üè¢ SERVICIO DE CHAT GENERATIVO EMPRESARIAL NIVEL 2025

# Standard library imports
import json
import logging
import os
import sys
import time
import uuid
from datetime import datetime
from typing import Dict, List, Any, Optional

# Third-party imports
import google.generativeai as genai  # type: ignore
from flask import current_app
from google.cloud import bigquery  # type: ignore
import requests

# Local imports
from smarwatt_auth import EnterpriseAuth
from utils.error_handlers import AppError
from utils.timezone_utils import now_spanish_iso
from app.services.enterprise_links_service import get_enterprise_link_service


# üß† INTEGRACI√ìN DIRECTA AI LEARNING SERVICE
# Importaci√≥n din√°mica para evitar dependencias circulares
def _get_ai_learning_service():
    """Factory para AI Learning Service con importaci√≥n din√°mica segura"""
    try:
        import sys
        import os

        # A√±adir path del expert_bot_api_COPY al sys.path temporalmente
        expert_bot_path = os.path.abspath(
            os.path.join(os.path.dirname(__file__), "../../../expert_bot_api_COPY")
        )

        if expert_bot_path not in sys.path:
            sys.path.insert(0, expert_bot_path)

        from app.services.ai_learning_service import AILearningService

        return AILearningService()

    except ImportError as e:
        logging.warning(f"‚ö†Ô∏è AI Learning Service no disponible: {str(e)}")
        return None
    except Exception as e:
        logging.error(f"‚ùå Error importando AI Learning Service: {str(e)}")
        return None


class EnterpriseGenerativeChatService:
    """
    üè¢ SERVICIO DE CHAT GENERATIVO EMPRESARIAL 2025
    Gestiona conversaciones con modelo de lenguaje grande (Gemini) con:
    - Aprendizaje autom√°tico totalmente integrado
    - Personalizaci√≥n empresarial m√°xima
    - An√°lisis de sentiment en tiempo real
    - Comunicaci√≥n robusta con expert_bot_api
    - Logging empresarial completo
    """

    def __init__(self) -> None:
        self.enterprise_auth: EnterpriseAuth = EnterpriseAuth()
        self.bigquery_client: Optional[bigquery.Client] = None
        self.model: Optional[Any] = None
        self.project_id: Optional[str] = None
        self.bq_dataset_id: Optional[str] = None
        self.interaction_log_table: Optional[str] = None
        self.learning_table: Optional[str] = None

        # üîó SERVICIO DE ENLACES EMPRESARIAL
        self.links_service = get_enterprise_link_service()

        # üß† AI LEARNING SERVICE INTEGRACI√ìN DIRECTA
        self.ai_learning_service = _get_ai_learning_service()
        if self.ai_learning_service:
            logging.info("‚úÖ AI Learning Service integrado exitosamente")
        else:
            logging.warning(
                "‚ö†Ô∏è AI Learning Service no disponible - usando an√°lisis b√°sico"
            )

        self._initialize_gemini_model()
        self._initialize_bigquery_client()

        logging.info("üè¢ EnterpriseGenerativeChatService inicializado con IA avanzada")

    def _initialize_gemini_model(self) -> None:
        """Inicializa el modelo Gemini con configuraci√≥n empresarial"""
        try:
            gemini_api_key = current_app.config.get("GEMINI_API_KEY")
            if not gemini_api_key:
                raise AppError("Clave API de Gemini no configurada", 500)

            genai.configure(api_key=gemini_api_key)

            # üß† INSTRUCCIONES EMPRESARIALES AVANZADAS PARA GEMINI
            self.system_instruction = self._build_enterprise_system_instruction()

            # Inicializar modelo con configuraci√≥n empresarial compatible
            self.model = genai.GenerativeModel(
                model_name="gemini-1.5-flash",
                generation_config=genai.types.GenerationConfig(
                    temperature=0.7,
                    top_p=0.9,
                    top_k=40,
                    max_output_tokens=2048,
                ),
                safety_settings=[
                    {
                        "category": "HARM_CATEGORY_HARASSMENT",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE",
                    },
                    {
                        "category": "HARM_CATEGORY_HATE_SPEECH",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE",
                    },
                    {
                        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE",
                    },
                    {
                        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE",
                    },
                ],
            )

            logging.info("‚úÖ Modelo Gemini empresarial inicializado")

        except Exception as e:
            logging.error(f"‚ùå Error inicializando Gemini: {str(e)}")
            raise AppError(f"Error inicializando servicio de chat: {str(e)}", 500)

    def _initialize_bigquery_client(self) -> None:
        """Inicializa cliente BigQuery para logging empresarial"""
        try:
            self.project_id = current_app.config.get("GCP_PROJECT_ID")
            self.bq_dataset_id = current_app.config.get("BQ_DATASET_ID")
            self.interaction_log_table = current_app.config.get(
                "BQ_CONVERSATIONS_TABLE_ID", "conversations_log"
            )
            self.learning_table = current_app.config.get(
                "BQ_LEARNING_TABLE_ID", "ai_learning_data"
            )

            if self.project_id:
                self.bigquery_client = bigquery.Client(project=self.project_id)
                logging.info("‚úÖ Cliente BigQuery empresarial inicializado")
            else:
                logging.warning("‚ö†Ô∏è GCP_PROJECT_ID no configurado - logging limitado")

        except Exception as e:
            logging.error(f"‚ùå Error inicializando BigQuery: {str(e)}")
            # No es cr√≠tico, contin√∫a sin logging a BigQuery

    def _build_enterprise_system_instruction(self) -> str:
        """Construye instrucciones del sistema empresariales"""
        return (
            "Eres WattBot, un especialista en energ√≠a de SmarWatt.\n\n"
            "PERSONALIDAD Y TONO OBLIGATORIO:\n"
            "- Conversaci√≥n totalmente natural, como hablas con un amigo cercano\n"
            "- Cero jerga t√©cnica, cero lenguaje robotizado\n"
            "- Respuestas directas sin rodeos\n"
            "- SIEMPRE saluda al usuario por su nombre cuando est√© disponible\n"
            "- PROHIBIDO ABSOLUTAMENTE usar asteriscos (*), negritas (**texto**), vi√±etas con *, emojis corporativos o cualquier formato markdown\n"
            "- Escribe en p√°rrafos normales, conversaci√≥n fluida\n"
            "- Si necesitas hacer una lista, usa simplemente n√∫meros (1., 2., 3.) o guiones (-) al inicio de l√≠nea, NUNCA asteriscos\n\n"
            "QU√â HACES:\n"
            "- Ayudas a entender y reducir facturas de luz\n"
            "- Analizas consumos energ√©ticos reales del usuario\n"
            "- Recomiendas tarifas y mejoras de eficiencia espec√≠ficas\n"
            "- Respondes sobre energ√≠a renovable y sostenibilidad\n\n"
            "C√ìMO TRABAJAS CON DATOS REALES:\n"
            "- OBLIGATORIO: Usa SIEMPRE los datos espec√≠ficos del usuario (comercializadora, coste, kWh, tarifa)\n"
            "- Da consejos basados en SUS cifras reales de la factura, no gen√©ricos\n"
            "- Menciona espec√≠ficamente su comercializadora, su coste mensual, su tarifa actual\n"
            "- Calcula ahorros potenciales usando sus datos exactos\n"
            "- Si tienes informaci√≥n completa de su factura, NO pidas m√°s datos\n\n"
            "PRIORIDAD M√ÅXIMA - PERSONALIZACI√ìN PREMIUM:\n"
            "- Si tienes su nombre: SAL√öDALO SIEMPRE\n"
            "- Si tienes su comercializadora: MENCI√ìNALA espec√≠ficamente\n"
            "- Si tienes su coste mensual: √öSALO para c√°lculos reales\n"
            "- Si tienes su tarifa: EVAL√öALA y RECOMIENDA alternativas espec√≠ficas\n"
            "- Si tienes su consumo por franjas: ANAL√çZALO y da consejos espec√≠ficos\n\n"
            "EJEMPLOS DE RESPUESTAS PREMIUM:\n"
            "- 'Hola Tomates Juanlu, veo que con Naturgy est√°s pagando 171‚Ç¨/mes con la Tarifa Por Uso Luz. Eso est√° bastante caro para tu consumo de 801 kWh/mes.'\n"
            "- 'Con tu distribuci√≥n de consumo actual, te recomiendo cambiar a una tarifa que te permita ahorrar en las horas valle.'\n"
            "- 'Bas√°ndome en tus datos reales, podr√≠as ahorrar unos 25‚Ç¨/mes cambiando de tarifa.'\n\n"
            "FORMATO DE RESPUESTA OBLIGATORIO:\n"
            "- P√°rrafos normales de conversaci√≥n\n"
            "- Si haces listas: usa n√∫meros (1., 2., 3.) o guiones simples (-) NUNCA asteriscos\n"
            "- Texto plano, sin negritas, sin cursivas, sin asteriscos\n"
            "- Conversaci√≥n fluida como si hablaras cara a cara\n\n"
            "NUNCA:\n"
            "- Pidas informaci√≥n que ya tienes disponible\n"
            "- Des respuestas gen√©ricas si tienes datos espec√≠ficos\n"
            "- Ignores el nombre del usuario\n"
            "- Olvides mencionar su comercializadora o tarifa actual\n"
            "- Uses asteriscos (*) o negritas (**) bajo ninguna circunstancia\n\n"
            "Eres un especialista premium que usa los datos reales del usuario para dar valor espec√≠fico y personalizado con conversaci√≥n 100% natural."
        )

    def start_new_chat(self) -> Any:
        """Inicia nueva sesi√≥n de chat empresarial"""
        try:
            if self.model is None:
                raise AppError(
                    "El modelo Gemini no est√° inicializado correctamente", 500
                )
            chat_session = self.model.start_chat(history=[])
            logging.info("üí¨ Nueva sesi√≥n de chat empresarial iniciada")
            return chat_session
        except Exception as e:
            logging.error(f"‚ùå Error iniciando chat: {str(e)}")
            raise AppError(f"Error iniciando sesi√≥n de chat: {str(e)}", 500)

    def send_message(
        self,
        chat_session: Any,
        user_message: str,
        user_context: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        üß† ENV√çO DE MENSAJE CON IA EMPRESARIAL AVANZADA
        Procesa mensaje con aprendizaje autom√°tico y personalizaci√≥n m√°xima
        """
        start_time = time.time()

        try:
            # üß† AN√ÅLISIS DE SENTIMENT EN TIEMPO REAL
            sentiment_analysis = self._analyze_message_sentiment(user_message)

            # üß† ENRIQUECIMIENTO CON CONTEXTO EMPRESARIAL
            enhanced_message = self._build_enhanced_message(
                user_message, user_context, sentiment_analysis
            )

            # üîß INCORPORAR INSTRUCCIONES DEL SISTEMA (COMPATIBLE CON VERSI√ìN ACTUAL)
            enhanced_message = f"{self.system_instruction}\n\n{enhanced_message}"

            # üìä COMUNICACI√ìN CON EXPERT_BOT_API SI ES NECESARIO
            if self._should_consult_expert_bot(user_message, user_context):
                expert_response = self._consult_expert_bot(user_message, user_context)
                enhanced_message = self._integrate_expert_response(
                    enhanced_message, expert_response
                )

            # üöÄ ENV√çO A GEMINI CON STREAMING EMPRESARIAL PARA EVITAR OOM
            try:
                # STREAMING: Evita cargar respuesta completa en memoria
                response_stream = chat_session.send_message(
                    enhanced_message, stream=True
                )
                full_response = ""

                # Procesar stream por chunks peque√±os
                for chunk in response_stream:
                    if chunk.text:
                        full_response += chunk.text

                # Crear objeto response compatible
                class StreamResponse:
                    def __init__(self, text):
                        self.text = text

                response = StreamResponse(full_response)
                logging.info(
                    f"‚úÖ Streaming exitoso - Respuesta: {len(full_response)} chars"
                )

            except Exception as streaming_error:
                logging.warning(
                    f"‚ö†Ô∏è Streaming fall√≥, usando m√©todo tradicional: {streaming_error}"
                )
                # FALLBACK: Si streaming falla, usar m√©todo original
                response = chat_session.send_message(enhanced_message)

            response_time = time.time() - start_time

            # üìà AN√ÅLISIS DE RESPUESTA PARA APRENDIZAJE
            response_analysis = self._analyze_response_quality(
                user_message, response.text, user_context
            )

            # üîó ENLACES INTELIGENTES SOLO CUANDO EL USUARIO LOS SOLICITA ESPEC√çFICAMENTE
            enhanced_response_with_links = self._add_links_if_user_requests(
                user_message, response.text
            )

            # üíæ LOGGING EMPRESARIAL COMPLETO
            interaction_data = self._log_enterprise_interaction(
                user_message,
                enhanced_response_with_links,  # üîó Usar respuesta con enlaces contextuales
                user_context,
                sentiment_analysis,
                response_analysis,
                response_time,
            )

            # üß† ACTUALIZACI√ìN DE APRENDIZAJE AUTOM√ÅTICO CON AI LEARNING SERVICE
            if user_context is not None:
                self._update_learning_patterns(user_context, interaction_data)

                # üî• PROCESAMIENTO AVANZADO CON AI LEARNING SERVICE
                if self.ai_learning_service and user_context.get("uid"):
                    try:
                        learning_data = {
                            "user_id": user_context["uid"],
                            "conversation_id": interaction_data.get(
                                "interaction_id", "unknown"
                            ),
                            "user_message": user_message,
                            "bot_response": enhanced_response_with_links,
                            "sentiment_analysis": sentiment_analysis,
                            "response_time": response_time,
                            "timestamp": now_spanish_iso(),
                        }

                        enterprise_analysis = (
                            self.ai_learning_service.process_enterprise_interaction(
                                learning_data
                            )
                        )

                        # A√±adir resultados empresariales a m√©tricas
                        interaction_data["enterprise_learning"] = enterprise_analysis

                        logging.info(
                            "‚úÖ Procesamiento empresarial AI Learning completado"
                        )

                    except Exception as e:
                        logging.warning(
                            f"‚ö†Ô∏è Error en procesamiento empresarial AI Learning: {str(e)}"
                        )
                        # Continuar sin fallar

            # üìä SERIALIZACI√ìN DE HISTORIAL
            serializable_history = self._serialize_chat_history(chat_session.history)

            return {
                "response_text": enhanced_response_with_links,  # üîó Respuesta con enlaces inteligentes
                "chat_history": serializable_history,
                "enterprise_metrics": {
                    "context_used": user_context is not None,
                    "ai_learning_applied": bool(
                        user_context and user_context.get("ai_learned_patterns")
                    ),
                    "sentiment_score": sentiment_analysis.get("score", 0.0),
                    "enterprise_sentiment_analysis": sentiment_analysis.get(
                        "enterprise_analysis", False
                    ),
                    "response_time": response_time,
                    "personalization_level": self._calculate_personalization_level(
                        user_context
                    ),
                    "expert_bot_consulted": self._should_consult_expert_bot(
                        user_message, user_context
                    ),
                    "quality_score": response_analysis.get("quality_score", 0.0),
                    "links_enhanced": enhanced_response_with_links
                    != response.text,  # üîó Flag de mejora
                    "ai_learning_service_active": self.ai_learning_service is not None,
                },
                "prompt_used": enhanced_message,
                "interaction_id": interaction_data.get("interaction_id"),
                "learning_updates": interaction_data.get("learning_updates", []),
            }

        except Exception as e:
            logging.error(f"‚ùå Error procesando mensaje: {str(e)}")
            return {
                "response_text": "Disculpa, he tenido un problema interno. Por favor, int√©ntalo de nuevo.",
                "chat_history": [],
                "enterprise_metrics": {"error": True, "error_message": str(e)},
            }

    def _analyze_message_sentiment(self, message: str) -> Dict[str, Any]:
        """Analiza sentiment del mensaje del usuario con AI Learning Service"""
        try:
            # üß† USAR AI LEARNING SERVICE SI EST√Å DISPONIBLE
            if self.ai_learning_service:
                try:
                    # Generar IDs temporales para el an√°lisis
                    temp_user_id = "temp_analysis_user"
                    temp_conversation_id = str(uuid.uuid4())

                    # An√°lisis empresarial avanzado
                    sentiment_analysis = (
                        self.ai_learning_service.analyze_sentiment_enterprise(
                            temp_user_id, temp_conversation_id, message
                        )
                    )

                    return {
                        "score": sentiment_analysis.sentiment_score,
                        "confidence": sentiment_analysis.confidence,
                        "sentiment_label": sentiment_analysis.sentiment_label,
                        "emotional_indicators": sentiment_analysis.emotional_indicators,
                        "personalization_hints": sentiment_analysis.personalization_hints,
                        "risk_factors": sentiment_analysis.risk_factors,
                        "engagement_level": sentiment_analysis.engagement_level,
                        "enterprise_analysis": True,
                        "timestamp": now_spanish_iso(),
                    }

                except Exception as e:
                    logging.warning(
                        f"‚ö†Ô∏è Error con AI Learning Service, usando an√°lisis b√°sico: {str(e)}"
                    )
                    # Continuar con an√°lisis b√°sico

            # üîÑ AN√ÅLISIS B√ÅSICO DE FALLBACK
            positive_keywords = [
                "gracias",
                "excelente",
                "perfecto",
                "genial",
                "bien",
                "bueno",
            ]
            negative_keywords = [
                "problema",
                "error",
                "mal",
                "malo",
                "frustrado",
                "dif√≠cil",
            ]

            message_lower = message.lower()
            positive_count = sum(
                1 for word in positive_keywords if word in message_lower
            )
            negative_count = sum(
                1 for word in negative_keywords if word in message_lower
            )

            # C√°lculo de score b√°sico
            score = 0.0
            if positive_count > negative_count:
                score = min(1.0, positive_count * 0.3)
            elif negative_count > positive_count:
                score = max(-1.0, negative_count * -0.3)

            return {
                "score": score,
                "confidence": abs(score),
                "positive_indicators": positive_count,
                "negative_indicators": negative_count,
                "message_length": len(message),
                "enterprise_analysis": False,
                "timestamp": now_spanish_iso(),
            }

        except Exception as e:
            logging.error(f"‚ùå Error analizando sentiment: {str(e)}")
            return {"score": 0.0, "confidence": 0.0, "error": str(e)}

    def _build_enhanced_message(
        self,
        user_message: str,
        user_context: Optional[Dict[str, Any]],
        sentiment_analysis: Dict[str, Any],
    ) -> str:
        """Construye mensaje enriquecido con contexto empresarial"""
        try:
            context_parts = ["=== üè¢ CONTEXTO EMPRESARIAL SMARWATT ==="]

            # üß† DATOS DEL USUARIO
            if user_context:
                context_parts.append(self._build_user_context_prompt(user_context))

            # üß† AN√ÅLISIS DE SENTIMENT CON AI LEARNING SERVICE
            if sentiment_analysis.get("score") != 0:
                context_parts.append(f"\nüß† AN√ÅLISIS DE SENTIMENT:")
                context_parts.append(
                    f"- Score emocional: {sentiment_analysis['score']:.2f}"
                )
                context_parts.append(
                    f"- Confianza: {sentiment_analysis['confidence']:.2f}"
                )

                # üî• INFORMACI√ìN AVANZADA SI EST√Å DISPONIBLE
                if sentiment_analysis.get("enterprise_analysis"):
                    context_parts.append("- An√°lisis: AI Learning Service (Avanzado)")

                    if sentiment_analysis.get("engagement_level"):
                        context_parts.append(
                            f"- Nivel engagement: {sentiment_analysis['engagement_level']}"
                        )

                    if sentiment_analysis.get("risk_factors"):
                        risk_count = len(sentiment_analysis["risk_factors"])
                        if risk_count > 0:
                            context_parts.append(
                                f"‚ö†Ô∏è Factores de riesgo detectados: {risk_count}"
                            )

                    if sentiment_analysis.get("personalization_hints"):
                        hints_count = len(sentiment_analysis["personalization_hints"])
                        if hints_count > 0:
                            context_parts.append(
                                f"üí° Hints personalizaci√≥n: {hints_count}"
                            )
                else:
                    context_parts.append("- An√°lisis: B√°sico (fallback)")

                if sentiment_analysis["score"] < -0.2:
                    context_parts.append(
                        "‚ö†Ô∏è USUARIO CON SENTIMENT NEGATIVO - Usar tono emp√°tico y soluciones espec√≠ficas"
                    )
                elif sentiment_analysis["score"] > 0.2:
                    context_parts.append(
                        "üòä USUARIO CON SENTIMENT POSITIVO - Mantener energ√≠a y ofrecer valor adicional"
                    )

            # üß† INSTRUCCIONES ESPEC√çFICAS PREMIUM
            context_parts.append(
                "\n=== üéØ INSTRUCCIONES CR√çTICAS PERSONALIZACI√ìN PREMIUM ==="
            )
            context_parts.append(
                "1. SALUDA OBLIGATORIAMENTE por su nombre si est√° disponible"
            )
            context_parts.append(
                "2. MENCIONA espec√≠ficamente su comercializadora, coste mensual y tarifa actual"
            )
            context_parts.append(
                "3. CALCULA ahorros usando SUS cifras exactas de factura"
            )
            context_parts.append(
                "4. PROPORCIONA recomendaciones espec√≠ficas para SU perfil de consumo"
            )
            context_parts.append("5. NUNCA pidas datos que ya tienes disponibles")
            context_parts.append("6. ADAPTA el tono seg√∫n el sentiment detectado")
            context_parts.append(
                "7. USA valores espec√≠ficos: X‚Ç¨/mes, Y kWh, Z comercializadora"
            )

            context_parts.append(f"\nüìù PREGUNTA DEL USUARIO: {user_message}")

            return "\n".join(context_parts)

        except Exception as e:
            logging.error(f"‚ùå Error construyendo mensaje enriquecido: {str(e)}")
            return user_message

    def _build_user_context_prompt(self, user_context: Dict[str, Any]) -> str:
        """
        üè¢ CONSTRUYE PROMPT EMPRESARIAL CON TODOS LOS DATOS DISPONIBLES

        Usa TODOS los datos disponibles para personalizaci√≥n m√°xima:
        - Datos personales y de factura completos
        - Datos de consumo por franjas horarias
        - Informaci√≥n de comercializadora y distribuidora
        - Datos del hogar y ubicaci√≥n
        - Patrones de aprendizaje autom√°tico

        DISE√ëO ROBUSTO: Funciona con datos completos, parciales o m√≠nimos
        """
        context_parts = []

        # ‚úÖ DATOS PERSONALES PRIORITARIOS
        if user_context.get("user_name"):
            context_parts.append(f"üë§ USUARIO: {user_context['user_name']}")

        # ‚úÖ DATOS DE FACTURA COMPLETOS (TODOS LOS 20+ CAMPOS)
        if user_context.get("last_invoice"):
            invoice = user_context["last_invoice"]
            context_parts.append("üìã DATOS COMPLETOS DE FACTURA:")

            # Datos cr√≠ticos b√°sicos
            if invoice.get("kwh_consumidos"):
                context_parts.append(
                    f"- Consumo total: {invoice['kwh_consumidos']} kWh/mes"
                )
            if invoice.get("coste_total"):
                context_parts.append(f"- Coste mensual: {invoice['coste_total']}‚Ç¨")

            # ‚úÖ COMERCIALIZADORA Y TARIFA (ANTES IGNORADOS)
            if invoice.get("comercializadora"):
                context_parts.append(
                    f"- Comercializadora actual: {invoice['comercializadora']}"
                )
            if invoice.get("tariff_name_from_invoice"):
                context_parts.append(
                    f"- Tarifa contratada: {invoice['tariff_name_from_invoice']}"
                )
            if invoice.get("tariff_type"):
                context_parts.append(f"- Tipo de tarifa: {invoice['tariff_type']}")

            # ‚úÖ CONSUMO POR FRANJAS HORARIAS (ANTES IGNORADOS)
            if (
                invoice.get("kwh_punta")
                or invoice.get("kwh_valle")
                or invoice.get("kwh_llano")
            ):
                context_parts.append("- Desglose horario:")
                if invoice.get("kwh_punta"):
                    context_parts.append(f"  ¬∑ Punta: {invoice['kwh_punta']} kWh")
                if invoice.get("kwh_valle"):
                    context_parts.append(f"  ¬∑ Valle: {invoice['kwh_valle']} kWh")
                if invoice.get("kwh_llano"):
                    context_parts.append(f"  ¬∑ Llano: {invoice['kwh_llano']} kWh")

            # ‚úÖ PRECIOS Y T√âRMINOS (ANTES IGNORADOS)
            if invoice.get("precio_kwh_punta"):
                context_parts.append(
                    f"- Precio punta: {invoice['precio_kwh_punta']:.4f}‚Ç¨/kWh"
                )
            if invoice.get("termino_energia"):
                context_parts.append(
                    f"- T√©rmino energ√≠a: {invoice['termino_energia']}‚Ç¨"
                )
            if invoice.get("termino_potencia"):
                context_parts.append(
                    f"- T√©rmino potencia: {invoice['termino_potencia']}‚Ç¨"
                )

            # ‚úÖ POTENCIA Y DATOS T√âCNICOS (ANTES IGNORADOS)
            if invoice.get("potencia_contratada_kw"):
                context_parts.append(
                    f"- Potencia contratada: {invoice['potencia_contratada_kw']} kW"
                )
            if invoice.get("potencia_maxima_demandada"):
                context_parts.append(
                    f"- Potencia m√°xima demandada: {invoice['potencia_maxima_demandada']} kW"
                )

            # ‚úÖ DISTRIBUIDORA Y UBICACI√ìN (ANTES IGNORADOS)
            if invoice.get("distribuidora"):
                context_parts.append(f"- Distribuidora: {invoice['distribuidora']}")
            if invoice.get("codigo_postal"):
                context_parts.append(f"- C√≥digo postal: {invoice['codigo_postal']}")

            # ‚úÖ DATOS TEMPORALES Y FACTURACI√ìN (ANTES IGNORADOS)
            if invoice.get("periodo_facturacion_dias"):
                context_parts.append(
                    f"- Per√≠odo facturaci√≥n: {invoice['periodo_facturacion_dias']} d√≠as"
                )
            if invoice.get("fecha_emision"):
                context_parts.append(f"- Fecha emisi√≥n: {invoice['fecha_emision']}")

            # ‚úÖ CALCULAR PORCENTAJES AUTOM√ÅTICAMENTE
            if invoice.get("peak_percent_from_invoice"):
                context_parts.append(
                    f"- Consumo en horas punta: {invoice['peak_percent_from_invoice']}%"
                )
            elif invoice.get("kwh_punta") and invoice.get("kwh_consumidos"):
                peak_percent = round(
                    (invoice["kwh_punta"] / invoice["kwh_consumidos"]) * 100, 1
                )
                context_parts.append(f"- Consumo en horas punta: {peak_percent}%")

        # ‚úÖ DATOS DEL HOGAR Y PERFIL (ANTES IGNORADOS PARCIALMENTE)
        household_info = []
        if user_context.get("home_type"):
            household_info.append(f"Tipo: {user_context['home_type']}")
        if user_context.get("num_inhabitants"):
            household_info.append(f"Habitantes: {user_context['num_inhabitants']}")
        if user_context.get("heating_type"):
            household_info.append(f"Calefacci√≥n: {user_context['heating_type']}")
        if user_context.get("has_ac"):
            household_info.append("Aire acondicionado: S√≠")
        if user_context.get("has_pool"):
            household_info.append("Piscina: S√≠")
        if user_context.get("is_teleworker"):
            household_info.append("Teletrabajo: S√≠")
        if user_context.get("has_solar_panels"):
            household_info.append("Paneles solares: S√≠")
        if user_context.get("post_code_prefix"):
            household_info.append(f"CP: {user_context['post_code_prefix']}")

        if household_info:
            context_parts.append(f"üè† PERFIL DEL HOGAR: {' | '.join(household_info)}")

        # ‚úÖ APRENDIZAJE AUTOM√ÅTICO Y PATRONES (MANTENIDO Y MEJORADO)
        if user_context.get("ai_learned_patterns"):
            patterns = user_context["ai_learned_patterns"]
            context_parts.append("üß† PATRONES APRENDIDOS:")

            if "communication_style" in patterns:
                style = patterns["communication_style"]["data"]
                context_parts.append(
                    f"- Estilo comunicaci√≥n: {style.get('formality_level', 'normal')}"
                )
                if style.get("message_length_preference"):
                    context_parts.append(
                        f"- Prefiere respuestas: {style['message_length_preference']}"
                    )

            if "interest_topics" in patterns:
                topics = patterns["interest_topics"]["data"]
                top_topics = [k for k, v in topics.items() if v > 0]
                if top_topics:
                    context_parts.append(
                        f"- Temas de inter√©s: {', '.join(top_topics[:3])}"
                    )

            if "satisfaction_history" in patterns:
                satisfaction_data = patterns["satisfaction_history"]["data"]
                if satisfaction_data:
                    avg_satisfaction = sum(
                        item.get("sentiment_score", 0)
                        for item in satisfaction_data[-3:]
                    ) / min(3, len(satisfaction_data))
                    if avg_satisfaction > 0.3:
                        context_parts.append("- Historial: Generalmente satisfecho")
                    elif avg_satisfaction < -0.3:
                        context_parts.append(
                            "- Historial: Ha tenido frustraciones previas"
                        )

        # ‚úÖ RESUMEN DE COMPLETITUD DE DATOS
        data_completeness = self._calculate_data_completeness(user_context)
        if data_completeness >= 90:
            context_parts.append(
                "üìä DATOS: Perfil completo (90%+) - M√°xima personalizaci√≥n disponible"
            )
        elif data_completeness >= 70:
            context_parts.append(
                "üìä DATOS: Perfil detallado (70%+) - Alta personalizaci√≥n"
            )
        elif data_completeness >= 50:
            context_parts.append(
                "üìä DATOS: Perfil b√°sico (50%+) - Personalizaci√≥n media"
            )
        else:
            context_parts.append(
                "üìä DATOS: Perfil m√≠nimo (<50%) - Personalizaci√≥n b√°sica"
            )

        return "\n".join(context_parts)

    def _calculate_data_completeness(self, user_context: Dict[str, Any]) -> float:
        """Calcula el porcentaje de completitud de datos del usuario (0-100)"""
        score = 0
        total_possible = 100

        # Datos b√°sicos (30 puntos)
        if user_context.get("user_name"):
            score += 10
        if user_context.get("last_invoice", {}).get("kwh_consumidos"):
            score += 10
        if user_context.get("last_invoice", {}).get("coste_total"):
            score += 10

        # Datos de factura avanzados (40 puntos)
        invoice = user_context.get("last_invoice", {})
        if invoice.get("comercializadora"):
            score += 8
        if invoice.get("kwh_punta") or invoice.get("kwh_valle"):
            score += 8
        if invoice.get("potencia_contratada_kw"):
            score += 8
        if invoice.get("distribuidora"):
            score += 8
        if invoice.get("tariff_name_from_invoice"):
            score += 8

        # Datos del hogar (20 puntos)
        if user_context.get("home_type"):
            score += 5
        if user_context.get("num_inhabitants"):
            score += 5
        if user_context.get("post_code_prefix"):
            score += 5
        if any(
            [
                user_context.get("has_ac"),
                user_context.get("has_pool"),
                user_context.get("heating_type"),
            ]
        ):
            score += 5

        # Aprendizaje autom√°tico (10 puntos)
        if user_context.get("ai_learned_patterns"):
            score += 10

        return min(100, score)

    def _should_consult_expert_bot(
        self, user_message: str, user_context: Optional[Dict[str, Any]]
    ) -> bool:
        """
        üéØ L√ìGICA ROBUSTA PARA CONSULTAR RECOMENDACIONES DE TARIFAS

        SOLO consulta el recomendador cuando el usuario ESPEC√çFICAMENTE pide:
        - Recomendaciones de tarifas
        - Comparaciones entre tarifas
        - Cambios de tarifa
        - An√°lisis de ahorro

        NO consulta para preguntas generales sobre precios o informaci√≥n
        """
        message_lower = user_message.lower()

        # üî• PALABRAS CLAVE ESPEC√çFICAS PARA RECOMENDACIONES (SIN FALSOS POSITIVOS)
        recommendation_keywords = [
            "recomienda",
            "recomi√©ndame",
            "recomiendame",
            "recomendaci√≥n",
            "recomendaciones",
            "mejor tarifa",
            "qu√© tarifa",
            "qu√© tarifas",
            "que tarifas",
            "cu√°l tarifa",
            "cual tarifa",
            "cu√°les tarifas",
            "cuales tarifas",
            "dime tarifas",
            "cambiar tarifa",
            "cambio tarifa",
            "cambio de tarifa",
            "cambiar de tarifa",
            "comparar tarifas",
            "comparar tarifa",
            "alternativas tarifas",
            "otras tarifas",
            "otras opciones tarifas",
            # üî• A√ëADIR PALABRAS CLAVE PARA PRECIOS ACTUALES
            "precio actual",
            "precio de la luz",
            "precio energ√≠a",
            "precio luz",
            "precios actuales",
            "precio hoy",
            "precio ahora",
            "cu√°nto cuesta",
            "cuanto cuesta",
            "coste actual",
            "coste energ√≠a",
            "tarifa actual",
            "precio kwh",
            "precio por kwh",
        ]

        # üî• PALABRAS CLAVE DE AHORRO CON CONTEXTO ESPEC√çFICO
        savings_with_context = [
            "ahorrar tarifa",
            "ahorro tarifa",
            "ahorrar con tarifa",
            "ahorro con tarifa",
            "ahorrar cambiando",
            "ahorro cambiando",
        ]

        # üî• VERIFICAR RECOMENDACIONES ESPEC√çFICAS
        has_recommendation_intent = any(
            keyword in message_lower for keyword in recommendation_keywords
        )

        # üî• VERIFICAR AHORRO CON CONTEXTO ESPEC√çFICO
        has_savings_intent = any(
            keyword in message_lower for keyword in savings_with_context
        )

        # üî• VERIFICAR SOLICITUDES DIRECTAS DE TARIFAS DISPONIBLES
        direct_tariff_requests = [
            "tarifas hay",
            "qu√© tarifas hay",
            "que tarifas hay",
            "tarifas existen",
            "tarifas disponibles",
            "opciones de tarifas",
            "opciones tarifas",
        ]

        has_direct_tariff_request = any(
            phrase in message_lower for phrase in direct_tariff_requests
        )

        # üî• CONDICI√ìN ROBUSTA: SOLO CONSULTAR SI HAY INTENCI√ìN CLARA DE RECOMENDACI√ìN
        should_consult = bool(
            has_recommendation_intent or has_savings_intent or has_direct_tariff_request
        )

        if should_consult:
            logging.info(
                f"üéØ Consultando recomendaciones de tarifas para: '{user_message[:50]}...'"
            )
        else:
            logging.info(
                f"‚ÑπÔ∏è Pregunta general sin necesidad de recomendaciones: '{user_message[:50]}...'"
            )

        return should_consult

    def _consult_expert_bot(
        self, user_message: str, user_context: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Consulta endpoint de datos del mercado de tarifas para precios actuales"""
        try:
            from flask import g

            # Verificar si tenemos token de autorizaci√≥n
            if not hasattr(g, "token") or not g.token:
                logging.warning(
                    "‚ö†Ô∏è No hay token disponible para consultar datos del mercado"
                )
                return {}

            # URL del endpoint correcto - DATOS DEL MERCADO CON PRECIOS REALES
            energy_ia_api_url = "http://localhost:8002"  # URL local del servicio actual

            market_data_url = f"{energy_ia_api_url}/api/v1/energy/tariffs/market-data"

            headers = {
                "Authorization": f"Bearer {g.token}",
                "Content-Type": "application/json",
            }

            response = requests.get(market_data_url, headers=headers, timeout=15)

            if response.status_code == 200:
                result: Dict[str, Any] = response.json()
                logging.info("‚úÖ Datos del mercado de tarifas obtenidos exitosamente")
                return result.get("data", {})
            else:
                logging.warning(
                    f"‚ö†Ô∏è Endpoint market-data respuesta: {response.status_code}"
                )
                return {}

        except Exception as e:
            logging.error(f"‚ùå Error consultando datos del mercado: {str(e)}")
            return {}

    def _integrate_expert_response(
        self, enhanced_message: str, expert_response: Dict[str, Any]
    ) -> str:
        """Integra datos del mercado de tarifas en el mensaje empresarial"""
        if not expert_response:
            return enhanced_message

        # ‚ö° PROCESAR DATOS DEL MERCADO DE TARIFAS
        if expert_response.get("tariffs"):
            tariffs = expert_response["tariffs"]
            market_stats = expert_response.get("market_statistics", {})

            market_data_context = (
                "\n\n=== ‚ö° DATOS ACTUALES DEL MERCADO EL√âCTRICO ===\n"
            )

            # Agregar estad√≠sticas del mercado
            if market_stats:
                total_tariffs = market_stats.get("total_tariffs", 0)
                providers = market_stats.get("providers", 0)
                last_updated = market_stats.get("last_updated", "")

                market_data_context += f"üìä Tarifas disponibles: {total_tariffs} de {providers} proveedores\n"
                if last_updated:
                    market_data_context += (
                        f"üìÖ √öltima actualizaci√≥n: {last_updated}\n\n"
                    )

            # Procesar tarifas con precios actuales
            pvpc_tariffs = []
            fixed_tariffs = []

            for tariff in tariffs[:10]:  # Top 10 tarifas
                provider = tariff.get("provider_name", "Proveedor")
                name = tariff.get("tariff_name", "Tarifa")
                tariff_type = tariff.get("tariff_type", "fixed")

                # Precios por kWh
                price_flat = tariff.get("kwh_price_flat")
                price_peak = tariff.get("kwh_price_peak")
                price_valley = tariff.get("kwh_price_valley")
                is_pvpc = tariff.get("is_pvpc", False)

                tariff_info = f"üè¢ {provider} - {name}\n"

                if is_pvpc:
                    tariff_info += "   üí° PVPC (Precio Variable del Mercado)\n"
                    pvpc_tariffs.append(tariff)
                else:
                    tariff_info += f"   üí° Tarifa {tariff_type.upper()}\n"
                    fixed_tariffs.append(tariff)

                # Mostrar precios seg√∫n disponibilidad
                if price_peak and price_valley:
                    tariff_info += f"   ‚ö° Punta: {price_peak:.3f}‚Ç¨/kWh\n"
                    tariff_info += f"   üåô Valle: {price_valley:.3f}‚Ç¨/kWh\n"
                elif price_flat:
                    tariff_info += f"   ‚ö° Precio fijo: {price_flat:.3f}‚Ç¨/kWh\n"

                tariff_info += "\n"
                market_data_context += tariff_info

            # Agregar an√°lisis de mercado
            if pvpc_tariffs and fixed_tariffs:
                market_data_context += (
                    "üí° AN√ÅLISIS: Disponibles tarifas fijas y variables (PVPC)\n"
                )
            elif pvpc_tariffs:
                market_data_context += (
                    "üí° AN√ÅLISIS: Principalmente tarifas variables (PVPC)\n"
                )
            elif fixed_tariffs:
                market_data_context += "üí° AN√ÅLISIS: Principalmente tarifas fijas\n"

            market_data_context += "\nINSTRUCCI√ìN: USA estos datos REALES del mercado para responder sobre precios actuales de la energ√≠a.\n"
            enhanced_message += market_data_context

        # Compatibilidad con respuestas de recomendaciones legacy
        elif expert_response.get("recommendations"):
            recommendations = expert_response["recommendations"]
            analysis_summary = expert_response.get("analysis_summary", {})

            tariff_recommendations = (
                "\n\n=== üéØ RECOMENDACIONES ESPEC√çFICAS DE TARIFAS ===\n"
            )

            # Agregar resumen del an√°lisis
            if analysis_summary:
                current_cost = analysis_summary.get("current_monthly_cost", 0)
                best_savings = analysis_summary.get("best_potential_savings", 0)
                tariff_recommendations += f"üí∞ Coste actual: {current_cost}‚Ç¨/mes\n"
                tariff_recommendations += (
                    f"üí∏ Mejor ahorro potencial: {best_savings}‚Ç¨/a√±o\n\n"
                )

            # Agregar top 3 recomendaciones
            for i, rec in enumerate(recommendations[:3], 1):
                provider = rec.get("provider_name", "Proveedor")
                tariff = rec.get("tariff_name", "Tarifa")
                monthly_cost = rec.get("cost_analysis", {}).get("monthly_cost", 0)
                savings = rec.get("potential_savings", 0)

                tariff_recommendations += f"{i}. {provider} - {tariff}\n"
                tariff_recommendations += f"   üíµ Coste: {monthly_cost}‚Ç¨/mes\n"
                tariff_recommendations += f"   üí∞ Ahorro: {savings}‚Ç¨/a√±o\n\n"

            tariff_recommendations += "INSTRUCCI√ìN: USA estas recomendaciones EXACTAS con nombres espec√≠ficos y ahorros calculados.\n"
            enhanced_message += tariff_recommendations

        # Mantener compatibilidad con respuestas legacy
        elif expert_response.get("analysis"):
            enhanced_message += (
                f"\n\n=== üéØ AN√ÅLISIS EXPERT_BOT ===\n{expert_response['analysis']}"
            )

        return enhanced_message

    def _analyze_response_quality(
        self, user_message: str, response: str, user_context: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Analiza calidad de la respuesta generada"""
        try:
            # M√©tricas b√°sicas de calidad
            response_length = len(response)
            question_answered = "?" in user_message and len(response) > 50
            specific_data_used = bool(
                user_context
                and any(
                    str(value) in response
                    for value in [
                        user_context.get("last_invoice", {}).get("kwh_consumidos"),
                        user_context.get("last_invoice", {}).get("coste_total"),
                        user_context.get("user_name"),
                    ]
                    if value
                )
            )

            # C√°lculo de score de calidad
            quality_score = 0.0
            if response_length > 100:
                quality_score += 0.3
            if question_answered:
                quality_score += 0.3
            if specific_data_used:
                quality_score += 0.4

            return {
                "quality_score": min(1.0, quality_score),
                "response_length": response_length,
                "question_answered": question_answered,
                "specific_data_used": specific_data_used,
                "timestamp": now_spanish_iso(),
            }

        except Exception as e:
            logging.error(f"‚ùå Error analizando calidad: {str(e)}")
            return {"quality_score": 0.0, "error": str(e)}

    def _log_enterprise_interaction(
        self,
        user_message: str,
        response: str,
        user_context: Optional[Dict[str, Any]],
        sentiment_analysis: Dict[str, Any],
        response_analysis: Dict[str, Any],
        response_time: float,
    ) -> Dict[str, Any]:
        """Registra interacci√≥n con m√©tricas empresariales"""
        try:
            interaction_id = str(uuid.uuid4())

            interaction_data = {
                "interaction_id": interaction_id,
                "timestamp": now_spanish_iso(),
                "user_message": user_message,
                "response": response,
                "response_time": response_time,
                "sentiment_score": sentiment_analysis.get("score", 0.0),
                "quality_score": response_analysis.get("quality_score", 0.0),
                "context_completeness": len(user_context) if user_context else 0,
                "personalization_level": self._calculate_personalization_level(
                    user_context
                ),
                "user_id": user_context.get("uid") if user_context else None,
                "service": "energy_ia_api_copy",
            }

            # Log a BigQuery si est√° disponible
            if self.bigquery_client:
                self._log_to_bigquery(interaction_data)

            logging.info(f"üìä Interacci√≥n empresarial registrada: {interaction_id}")

            return interaction_data

        except Exception as e:
            logging.error(f"‚ùå Error logging empresarial: {str(e)}")
            return {"interaction_id": "error", "error": str(e)}

    def _log_to_bigquery(self, interaction_data: Dict[str, Any]) -> None:
        """Registra en BigQuery para an√°lisis empresarial - USANDO CAMPOS CORRECTOS DE conversations_log"""
        try:
            if not self.bigquery_client:
                return

            table_ref = self.bigquery_client.dataset(self.bq_dataset_id).table(
                self.interaction_log_table
            )

            # USAR SOLO CAMPOS EXACTOS DE conversations_log - 16 CAMPOS COMPLETOS
            row = {
                "conversation_id": interaction_data.get("interaction_id", ""),
                "message_id": f"{interaction_data.get('interaction_id', '')}_msg",
                "user_id": interaction_data.get("user_id", ""),
                "timestamp_utc": interaction_data["timestamp"],
                "sender": "user",
                "message_text": interaction_data.get("user_message", ""),
                "intent_detected": interaction_data.get("intent", ""),
                "bot_action": "response",
                "sentiment": interaction_data.get("sentiment_score", "neutral"),
                "deleted": False,
                "deleted_at": None,
                "response_text": interaction_data.get("response", ""),
                "context_completeness": interaction_data.get(
                    "personalization_level", 0
                ),
                "response_time_ms": int(
                    interaction_data.get("response_time", 0) * 1000
                ),
                "session_info": json.dumps(
                    {
                        "user_agent": "energy_ia_chatbot",
                        "platform": "web",
                        "version": "2025.1",
                        "api_version": "v1",
                    }
                ),
                "metadata": json.dumps(
                    {
                        "service": "energy_ia_api",
                        "endpoint": "generative_chat",
                        "features_used": interaction_data.get("features_used", []),
                        "personalization_data": interaction_data.get(
                            "personalization_data", {}
                        ),
                    }
                ),
            }

            errors = self.bigquery_client.insert_rows_json(table_ref, [row])
            if errors:
                logging.error(f"‚ùå Error insertando en BigQuery: {errors}")
            else:
                logging.info(
                    f"‚úÖ Interacci√≥n guardada en BigQuery: {interaction_data.get('interaction_id', 'unknown')}"
                )

        except Exception as e:
            logging.error(f"‚ùå Error logging BigQuery: {str(e)}")

    def _update_learning_patterns(
        self, user_context: Dict[str, Any], interaction_data: Dict[str, Any]
    ) -> None:
        """Actualiza patrones de aprendizaje autom√°tico"""
        try:
            if not user_context or not user_context.get("uid"):
                return

            # Actualizar patrones de comunicaci√≥n
            if "ai_learned_patterns" not in user_context:
                user_context["ai_learned_patterns"] = {}

            patterns = user_context["ai_learned_patterns"]

            # Actualizar estilo de comunicaci√≥n
            if "communication_style" not in patterns:
                patterns["communication_style"] = {
                    "data": {},
                    "updated": now_spanish_iso(),
                }

            comm_style = patterns["communication_style"]["data"]

            # Analizar longitud de mensaje preferida
            message_length = len(interaction_data["user_message"])
            if message_length > 200:
                comm_style["message_length_preference"] = "long"
            elif message_length < 50:
                comm_style["message_length_preference"] = "short"
            else:
                comm_style["message_length_preference"] = "medium"

            # Actualizar nivel de satisfacci√≥n
            if "satisfaction_history" not in patterns:
                patterns["satisfaction_history"] = {
                    "data": [],
                    "updated": now_spanish_iso(),
                }

            satisfaction_data = patterns["satisfaction_history"]["data"]
            satisfaction_data.append(
                {
                    "timestamp": interaction_data["timestamp"],
                    "sentiment_score": interaction_data["sentiment_score"],
                    "quality_score": interaction_data["quality_score"],
                }
            )

            # Mantener solo √∫ltimos 10 registros
            if len(satisfaction_data) > 10:
                satisfaction_data = satisfaction_data[-10:]

            patterns["satisfaction_history"]["data"] = satisfaction_data

            logging.info(f"üß† Patrones de aprendizaje actualizados para usuario")

        except Exception as e:
            logging.error(f"‚ùå Error actualizando patrones: {str(e)}")

    def _calculate_personalization_level(
        self, user_context: Optional[Dict[str, Any]]
    ) -> str:
        """Calcula nivel de personalizaci√≥n aplicado"""
        if not user_context:
            return "none"

        score = 0

        if user_context.get("user_name"):
            score += 1
        if user_context.get("last_invoice"):
            score += 2
        if user_context.get("ai_learned_patterns"):
            score += 3
        if user_context.get("home_type"):
            score += 1

        if score >= 6:
            return "maximum"
        elif score >= 4:
            return "high"
        elif score >= 2:
            return "medium"
        elif score >= 1:
            return "low"
        else:
            return "none"

    def _serialize_chat_history(self, history: List[Any]) -> List[Dict[str, Any]]:
        """Serializa historial de chat"""
        try:
            serializable_history = []

            for content in history:
                try:
                    serializable_history.append(
                        {
                            "role": content.role,
                            "parts": [
                                part.text if hasattr(part, "text") else str(part)
                                for part in content.parts
                            ],
                            "timestamp": now_spanish_iso(),
                        }
                    )
                except Exception as e:
                    logging.warning(f"‚ö†Ô∏è Error serializando historial: {str(e)}")

            return serializable_history

        except Exception as e:
            logging.error(f"‚ùå Error serializando historial: {str(e)}")
            return []

    def _add_links_if_user_requests(self, user_message: str, response_text: str) -> str:
        """
        üîó A√±ade enlaces SOLO cuando el usuario los solicita espec√≠ficamente

        Args:
            user_message: Mensaje original del usuario
            response_text: Respuesta generada por el chatbot

        Returns:
            str: Respuesta con enlaces HTML solo si el usuario los solicit√≥
        """
        try:
            if not user_message or not response_text:
                return response_text

            user_message_lower = user_message.lower()

            # Solo a√±adir enlaces si el usuario EXPL√çCITAMENTE los solicita
            user_requests_help = any(
                word in user_message_lower
                for word in [
                    "ayuda",
                    "ay√∫dame",
                    "help",
                    "soporte",
                    "contacto",
                    "contactar",
                ]
            )

            user_requests_articles = any(
                word in user_message_lower
                for word in [
                    "art√≠culo",
                    "art√≠culos",
                    "blog",
                    "leer m√°s",
                    "m√°s informaci√≥n",
                    "informaci√≥n adicional",
                ]
            )

            user_requests_tools = any(
                word in user_message_lower
                for word in [
                    "calculadora",
                    "calcular",
                    "herramienta",
                    "simular",
                    "simulaci√≥n",
                ]
            )

            # Solo aplicar enlaces si hay solicitud espec√≠fica del usuario
            if user_requests_help or user_requests_articles or user_requests_tools:
                return self.links_service.analyze_and_enhance_response(response_text)

            # Si no hay solicitud espec√≠fica, devolver respuesta original
            return response_text

        except Exception as e:
            logging.error(f"‚ùå Error en an√°lisis contextual de enlaces: {str(e)}")
            return response_text

    def get_enterprise_metrics(self) -> Dict[str, Any]:
        """Obtiene m√©tricas empresariales del servicio"""
        try:
            base_metrics = {
                "service_status": "active",
                "model_initialized": self.model is not None,
                "bigquery_connected": self.bigquery_client is not None,
                "auth_system": "active",
                "ai_learning_service_connected": self.ai_learning_service is not None,
                "timestamp": now_spanish_iso(),
                "version": "2025_enterprise",
            }

            # üß† M√âTRICAS AVANZADAS DEL AI LEARNING SERVICE
            if self.ai_learning_service:
                try:
                    ai_metrics = (
                        self.ai_learning_service.get_enterprise_performance_metrics()
                    )
                    base_metrics["ai_learning_metrics"] = ai_metrics
                    base_metrics["ai_learning_status"] = "active"
                except Exception as e:
                    logging.warning(
                        f"‚ö†Ô∏è Error obteniendo m√©tricas AI Learning: {str(e)}"
                    )
                    base_metrics["ai_learning_status"] = "error"
                    base_metrics["ai_learning_error"] = str(e)
            else:
                base_metrics["ai_learning_status"] = "not_available"

            return base_metrics

        except Exception as e:
            logging.error(f"‚ùå Error obteniendo m√©tricas: {str(e)}")
            return {"service_status": "error", "error": str(e)}


# üè¢ FUNCI√ìN FACTORY EMPRESARIAL PARA CHAT SERVICE
# Esta funci√≥n garantiza compatibilidad con toda la aplicaci√≥n

# Instancia singleton para compatibilidad empresarial
_enterprise_chat_service_instance = None


def get_enterprise_chat_service():
    """
    Factory function empresarial para obtener instancia de Chat Service

    Returns:
        EnterpriseGenerativeChatService: Instancia singleton del servicio

    Raises:
        AppError: Si hay problemas de configuraci√≥n o inicializaci√≥n
    """
    global _enterprise_chat_service_instance

    if _enterprise_chat_service_instance is None:
        try:
            _enterprise_chat_service_instance = EnterpriseGenerativeChatService()
            logger.info(
                "üè¢ Factory function: EnterpriseGenerativeChatService inicializado"
            )
        except Exception as e:
            logger.error(f"‚ùå Error en factory function Chat: {str(e)}")
            raise AppError(f"Error inicializando Chat service: {str(e)}", 500)

    return _enterprise_chat_service_instance


logger = logging.getLogger(__name__)
logger.info("‚úÖ M√≥dulo EnterpriseGenerativeChatService cargado correctamente")

# üîÑ ALIAS DE COMPATIBILIDAD EMPRESARIAL
# Mantiene compatibilidad con c√≥digo existente que usa GenerativeChatService
GenerativeChatService = EnterpriseGenerativeChatService

logger.info("‚úÖ Alias de compatibilidad GenerativeChatService creado")
